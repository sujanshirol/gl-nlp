{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-07T05:39:51.444908Z","iopub.execute_input":"2021-07-07T05:39:51.445926Z","iopub.status.idle":"2021-07-07T05:39:51.459175Z","shell.execute_reply.started":"2021-07-07T05:39:51.445692Z","shell.execute_reply":"2021-07-07T05:39:51.457987Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/quora-insincere-questions-classification/sample_submission.csv\n/kaggle/input/quora-insincere-questions-classification/embeddings.zip\n/kaggle/input/quora-insincere-questions-classification/train.csv\n/kaggle/input/quora-insincere-questions-classification/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from gensim.parsing.preprocessing import remove_stopwords\nfrom sklearn.model_selection import train_test_split\n\ndata = pd.read_csv('/kaggle/input/quora-insincere-questions-classification/train.csv').sample(10000)\ndocs = data['question_text'].fillna('NA').str.replace('[^a-z\\s]', '')\ntrain_x, validate_x, train_y, validate_y = train_test_split(docs, data['target'], test_size=0.2,\n                                                           random_state=1)\ndata.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-07T05:53:32.293946Z","iopub.execute_input":"2021-07-07T05:53:32.294339Z","iopub.status.idle":"2021-07-07T05:53:36.316522Z","shell.execute_reply.started":"2021-07-07T05:53:32.294314Z","shell.execute_reply":"2021-07-07T05:53:36.315266Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n  \"\"\"\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(100000, 3)"},"metadata":{}}]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Bidirectional, GRU\nfrom keras.layers.embeddings import Embedding\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras import backend as K\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-07-07T05:40:28.062670Z","iopub.execute_input":"2021-07-07T05:40:28.062960Z","iopub.status.idle":"2021-07-07T05:40:33.161093Z","shell.execute_reply.started":"2021-07-07T05:40:28.062936Z","shell.execute_reply":"2021-07-07T05:40:33.160491Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(train_x)\nvocab_size = len(tokenizer.word_index) + 1\n\nencoded_docs_train_x = tokenizer.texts_to_sequences(train_x)\nencoded_docs_validate_x = tokenizer.texts_to_sequences(validate_x)\nmax_length = max([len(x) for x in encoded_docs_train_x])\npadded_docs_train_x = pad_sequences(encoded_docs_train_x, maxlen=max_length, padding='post')\npadded_docs_validate_x = pad_sequences(encoded_docs_validate_x, maxlen=max_length, padding='post')","metadata":{"execution":{"iopub.status.busy":"2021-07-07T05:40:33.162166Z","iopub.execute_input":"2021-07-07T05:40:33.162511Z","iopub.status.idle":"2021-07-07T05:40:33.483267Z","shell.execute_reply.started":"2021-07-07T05:40:33.162477Z","shell.execute_reply":"2021-07-07T05:40:33.481899Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Model with trainable word emebddings","metadata":{}},{"cell_type":"code","source":"def recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","metadata":{"execution":{"iopub.status.busy":"2021-07-07T05:40:36.433336Z","iopub.execute_input":"2021-07-07T05:40:36.433631Z","iopub.status.idle":"2021-07-07T05:40:36.439636Z","shell.execute_reply.started":"2021-07-07T05:40:36.433607Z","shell.execute_reply":"2021-07-07T05:40:36.438774Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"embedding_dim = 300\n\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, embedding_dim, trainable=True))\nmodel.add(Bidirectional(LSTM(64, activation='tanh')))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', f1_m])","metadata":{"execution":{"iopub.status.busy":"2021-07-07T05:06:48.798116Z","iopub.execute_input":"2021-07-07T05:06:48.798457Z","iopub.status.idle":"2021-07-07T05:06:49.240725Z","shell.execute_reply.started":"2021-07-07T05:06:48.798428Z","shell.execute_reply":"2021-07-07T05:06:49.239941Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\nmodel.fit(padded_docs_train_x, train_y, \n          epochs=2, verbose=1, \n          batch_size=1024,\n          callbacks=[callback],\n         validation_data=(padded_docs_validate_x, validate_y),)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T05:06:52.703850Z","iopub.execute_input":"2021-07-07T05:06:52.704136Z","iopub.status.idle":"2021-07-07T05:09:07.106716Z","shell.execute_reply.started":"2021-07-07T05:06:52.704111Z","shell.execute_reply":"2021-07-07T05:09:07.105435Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Epoch 1/2\n79/79 [==============================] - 68s 836ms/step - loss: 0.3425 - accuracy: 0.9336 - f1_m: 0.0188 - val_loss: 0.1434 - val_accuracy: 0.9460 - val_f1_m: 0.4742\nEpoch 2/2\n79/79 [==============================] - 66s 836ms/step - loss: 0.1199 - accuracy: 0.9537 - f1_m: 0.5624 - val_loss: 0.1331 - val_accuracy: 0.9493 - val_f1_m: 0.5488\n","output_type":"stream"},{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f365de4cf10>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Model using Pre-trained Word Embeddings","metadata":{}},{"cell_type":"code","source":"from zipfile import ZipFile\nzip_path = '/kaggle/input/quora-insincere-questions-classification/embeddings.zip'\nzf = ZipFile(zip_path)\nzf.filelist","metadata":{"execution":{"iopub.status.busy":"2021-07-07T05:41:03.112136Z","iopub.execute_input":"2021-07-07T05:41:03.112636Z","iopub.status.idle":"2021-07-07T05:41:03.126513Z","shell.execute_reply.started":"2021-07-07T05:41:03.112605Z","shell.execute_reply":"2021-07-07T05:41:03.125430Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"[<ZipInfo filename='GoogleNews-vectors-negative300/' filemode='drwxrwxr-x' external_attr=0x10>,\n <ZipInfo filename='glove.840B.300d/' filemode='drwxrwxr-x' external_attr=0x10>,\n <ZipInfo filename='paragram_300_sl999/' filemode='drwxr-xr-x' external_attr=0x10>,\n <ZipInfo filename='wiki-news-300d-1M/' filemode='drwxrwxr-x' external_attr=0x10>,\n <ZipInfo filename='glove.840B.300d/glove.840B.300d.txt' compress_type=deflate filemode='-rw-rw-r--' file_size=5646236541 compress_size=2178478737>,\n <ZipInfo filename='GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin' compress_type=deflate filemode='-rw-rw-r--' file_size=3644258522 compress_size=1746270195>,\n <ZipInfo filename='wiki-news-300d-1M/wiki-news-300d-1M.vec' compress_type=deflate filemode='-rw-r--r--' file_size=2259088777 compress_size=682384991>,\n <ZipInfo filename='paragram_300_sl999/README.txt' compress_type=deflate filemode='-rw-r--r--' file_size=731 compress_size=441>,\n <ZipInfo filename='paragram_300_sl999/paragram_300_sl999.txt' compress_type=deflate filemode='-rw-r-----' file_size=4555969303 compress_size=1788784124>]"},"metadata":{}}]},{"cell_type":"markdown","source":"### Read Glove Embeddings Text File\n- Open the zip file\n- Go to each line\n    - Split the line by space\n    - First element is the word\n    - Remaining elements are the vector representation of the word\n    - Update the dictionary(key=word; value=vector)","metadata":{}},{"cell_type":"code","source":"vocab = tokenizer.word_index.keys()","metadata":{"execution":{"iopub.status.busy":"2021-07-07T05:49:32.101241Z","iopub.execute_input":"2021-07-07T05:49:32.101654Z","iopub.status.idle":"2021-07-07T05:49:32.106238Z","shell.execute_reply.started":"2021-07-07T05:49:32.101628Z","shell.execute_reply":"2021-07-07T05:49:32.105213Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"glove_path = 'glove.840B.300d/glove.840B.300d.txt'\n\nwith zf.open(glove_path) as file:\n    embeddings = {}\n    for line in file:\n        line = line.decode('utf-8').replace('\\n', '').split(' ')\n        word = line[0]\n        if word in vocab:\n            vector = line[1:]\n            vector = [float(x) for x in vector]\n            embeddings[word] = vector","metadata":{"execution":{"iopub.status.busy":"2021-07-07T05:41:27.766234Z","iopub.execute_input":"2021-07-07T05:41:27.766552Z","iopub.status.idle":"2021-07-07T05:44:03.741877Z","shell.execute_reply.started":"2021-07-07T05:41:27.766526Z","shell.execute_reply":"2021-07-07T05:44:03.740594Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"embedding_dim = len(vector)\nembedding_matrix = np.zeros((vocab_size, embedding_dim))\nfor word, index in tokenizer.word_index.items():\n    if word in embeddings:\n        embedding_matrix[index] = embeddings[word]","metadata":{"execution":{"iopub.status.busy":"2021-07-07T05:51:51.119147Z","iopub.execute_input":"2021-07-07T05:51:51.119482Z","iopub.status.idle":"2021-07-07T05:51:51.298313Z","shell.execute_reply.started":"2021-07-07T05:51:51.119458Z","shell.execute_reply":"2021-07-07T05:51:51.297692Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(vocab_size, embedding_dim, weights=[embedding_matrix]))\nmodel.add(Bidirectional(LSTM(64, activation='tanh')))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', f1_m])\n\ncallback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\nmodel.fit(padded_docs_train_x, train_y, \n          epochs=5, verbose=1, \n          batch_size=1024,\n          callbacks=[callback],\n         validation_data=(padded_docs_validate_x, validate_y),)","metadata":{"execution":{"iopub.status.busy":"2021-07-07T05:53:07.069617Z","iopub.execute_input":"2021-07-07T05:53:07.069920Z","iopub.status.idle":"2021-07-07T05:53:23.780025Z","shell.execute_reply.started":"2021-07-07T05:53:07.069894Z","shell.execute_reply":"2021-07-07T05:53:23.779051Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Epoch 1/2\n8/8 [==============================] - 10s 837ms/step - loss: 0.5719 - accuracy: 0.7582 - f1_m: 0.0223 - val_loss: 0.2649 - val_accuracy: 0.9365 - val_f1_m: 0.0000e+00\nEpoch 2/2\n8/8 [==============================] - 6s 709ms/step - loss: 0.2509 - accuracy: 0.9353 - f1_m: 0.0000e+00 - val_loss: 0.2374 - val_accuracy: 0.9365 - val_f1_m: 0.0000e+00\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fe763047950>"},"metadata":{}}]}]}